{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku_7CTHnoUgm"
   },
   "source": [
    "**The Concept**\n",
    "\n",
    "Linear regression attempts to model the relation of dependent and independent variables by fitting a linear equation. \n",
    "\n",
    "Suppose we have the data of quiz scores and the length of study hours of 100 students as shown here:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/691/1*fDfhpbBM67W-wPsyfX886g.png)\n",
    "\n",
    "By visually inspecting the scatter plot, we can easily draw a line with the equation *y=mx+b* , where \"m\" and \"b\" are the slope and y-intercept, respectively. These can be seen on the figure as roughly 40 and 0 for m and b respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1Fr0VGBoOHb"
   },
   "source": [
    "Let’s draw a line where m=40 and b=0.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/696/1*J0dPncPRUdNQxgs7TgL60g.png)\n",
    "\n",
    "The *y=40x* line looks good! \n",
    "\n",
    "We can then estimate that a student’s score is just 40 multiplied by the number of hours a student studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW65Qui4sv6w"
   },
   "source": [
    "Linear regression works exactly like this except that it cannot visually check the slope and y-intercept from the scatter plot. What it does instead is to guess the slope and y-intercept first, then measure how good its guess is. If it’s not good enough then it adjusts the slope and y-intercept until the line fits the data well.\n",
    "\n",
    "Linear regression is a three-step algorithm:\n",
    "\n",
    "1.   Initialize the parameters of a linear equation (first guess of slope and y-intercept).\n",
    "2.   Measure the goodness of fit based on some function.\n",
    "1.   Adjust the parameters until the measure in step 2 looks good.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1UJsPdWtc6B"
   },
   "source": [
    "**1.** **Linear Equation and Initialization**\n",
    "\n",
    "Now that we built our intuition around linear regression, let’s talk about each of the step mathematically.\n",
    "\n",
    "The first step in linear regression model is to initialize a linear equation; yes, we’ll use y=mx+b but we have to generalize our approach. \n",
    "The reason for such is that we might be facing data with multiple independent variables. \n",
    "\n",
    "Think of it as adding another variable in our Quiz Score data such as the amount of coffee consumed while studying. Having this coffee dimension will make the linear equation look like this: *y = m1x1 + m2x2 + b* , where m1 and m2 are slopes for the study hours and coffee dimensions respectively, and x1 and x2 are the study hours and coffee variables.\n",
    "\n",
    "\n",
    "We’ll use dot product to represent the product of matrices, m and x, instead of writing a longer equation for every new variable. Note that it is also valid to use the term tensor since it is the generalization of a matrix. The linear equation should be written as **y = m⋅x + b**.\n",
    "\n",
    "There are many ways to initialize the parameters of the equation, the most common ones are using random values, zeros, or ones. You are free to use any type of initialization, this choice will determine how fast your learning algorithm terminates. In the next iteration of the algorithm, these parameters will be updated based on some function that we'll discuss in step 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIJJGqeCtdJ2"
   },
   "source": [
    "**2. Loss Function**\n",
    "\n",
    "Now let’s say the initial values you set for m and b are ones, so your equation is `y = 1x + 1` .\n",
    "\n",
    "The initial predictions will look like the orange dots in the figure below. It’s obviously a very bad prediction, we need a number to quantify how bad or good these predictions are.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/691/1*X-1q5DK6xYxBrWxNjTdelA.png)\n",
    "\n",
    "There are many ways to measure the goodness of our prediction, we’ll use one of them called mean squared error (MSE). In this context, error means difference, so MSE literally means taking the square of the difference between actual and predicted values, then take the average. It is written mathematically as:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/591/0*L2cG_FchQ00t06yk.png)\n",
    "\n",
    "Functions like MSE are called loss function or objective function. These are functions that the algorithm wants to minimize. \n",
    "\n",
    "If our linear regression model perfectly predicts the quiz scores, its MSE will be equal to 0. So in every iteration of the algorithm, it should update the parameters such that the MSE comes closer to 0 without overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtNU7Y0Q2Zwb"
   },
   "source": [
    "**3. Gradient Descent**\n",
    "\n",
    "Sure we can keep on guessing the parameters until we get close enough to zero MSE but it will take time and effort — gradient descent will do this for us. \n",
    "\n",
    "Gradient descent is one of the building blocks of artificial intelligence. Algorithms like gradient descent allows learning algorithms to learn without being told so explicitly. \n",
    "\n",
    "Gradient descent is an optimization algorithm that we will use to minimize our loss function (MSE in this case). It does so by updating the parameters with small changes in each iteration, this change can be big too depending on your preference (learning rate).\n",
    "\n",
    "In each new iteration, the updated parameters will be\n",
    "\n",
    " `p_new = p_old - (l*dL/dp)`\n",
    "\n",
    "where p is the parameter which could be the slope m, or the y-intercept b. \n",
    "\n",
    "The new variables, l and dL/dp, are the learning rate and partial derivative of the loss function with respect to the parameter.\n",
    "\n",
    "With enough iterations, the slope and y-intercept will get closer to 40 and 0, the values we consider to be “close enough” to fit to our data. As you may have observed, if you happen to initialize the parameters close to 40 and 0, say 35 and 0.5, then the algorithm will take less iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftbffWiA3Riq"
   },
   "source": [
    "**Stopping Criteria**\n",
    "\n",
    "Here are some of the possible ways to terminate the algorithm:\n",
    "\n",
    "\n",
    "1.   Terminate the algorithm once a specified number of iterations is satisfied.\n",
    "2.   Terminate the algorithm once a specified MSE is satisfied.\n",
    "1.   Terminate the algorithm if the MSE does not improve in the next iteration. You can specify a precision such as 0.001, if the difference between two successive MSEs is less than this precision, then stop the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOBWT608ntcc"
   },
   "source": [
    "The following code demo will walk you through how to implement linear regression from scratch using only Tensorflow.\n",
    "\n",
    "Here, we’ll follow the three-step approach to linear regression algorithm discussed above and terminate the algorithm using stopping criteria 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70N-yJ3f4Hm_"
   },
   "source": [
    "**Import libraries**\n",
    "\n",
    "These are the only libraries we’ll need for this demo - TensorFlow for building the algorithm, pyplot for visualization purposes, and boston_housing as our toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3103,
     "status": "ok",
     "timestamp": 1635853030787,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "h8d75F9G3-zd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzn_jDjW47Sm"
   },
   "source": [
    "**1. Initialize a linear equation**\n",
    "\n",
    "Let’s start off by creating a SimpleLinearRegression class with initialization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1635853034149,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "qn-Q-i5U4ZD4"
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self, initializer='random'):\n",
    "        if initializer=='ones':\n",
    "            self.var = 1.\n",
    "        elif initializer=='zeros':\n",
    "            self.var = 0.\n",
    "        elif initializer=='random':\n",
    "            self.var = tf.random.uniform(shape=[], minval=0., maxval=1.)\n",
    "            \n",
    "        self.m = tf.Variable(1., shape=tf.TensorShape(None))\n",
    "        self.b = tf.Variable(self.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfR7zieU5xJI"
   },
   "source": [
    "Here the class is specified with three initialization options - ones, zeros, and random (default). \n",
    "\n",
    "`tf.random.uniform` will generate a tensor with random values from uniform distribution within the range `minval` and `maxval` with shape `shape`. \n",
    "\n",
    "We've defined m as a variable with no particular shape so it can be flexible enough to accept any number of independent variables, this can be done by setting `shape = tf.TensorShape(None)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRfghEp57dI5"
   },
   "source": [
    "**2. Loss Function**\n",
    "\n",
    "Next is to implement our loss function, MSE. Following is the implementation of the function in TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1107,
     "status": "ok",
     "timestamp": 1635853041159,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "G3jOU5-a5s4k"
   },
   "outputs": [],
   "source": [
    "def mse(self, true, predicted):\n",
    "        return tf.reduce_mean(tf.square(true-predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOC5vHa97xgg"
   },
   "source": [
    "This is fairly easy to write in Tensorflow. \n",
    "\n",
    "First you take the difference of `true and predicted value`, use `tf.square` to square the differences then get the mean of the squared differences using `tf.reduce_mean` .\n",
    "\n",
    "This function accepts true and predicted values where the former comes from the data itself, but the latter have to be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1635853043868,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "DjC2EQgQ7oHj"
   },
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "        return tf.reduce_sum(self.m * x, 1) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujTkPsTD8JtC"
   },
   "source": [
    "The predict method is done by simplifying the linear equation. \n",
    "\n",
    "First we take the dot product of `m (slope tensor)` and `x (feature tensor)` and add the `y-intercept b`. \n",
    "\n",
    "We have to specify the axis to which the reduction in `reduction_sum` will be computed to 1 , otherwise it will reduce the tensor to a single sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwqTpcoj8rOO"
   },
   "source": [
    "**3. Updating the parameters**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1635853048482,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "KeN0Xk0B8FQx"
   },
   "outputs": [],
   "source": [
    "def update(self, X, y, learning_rate):\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            loss = self.mse(y, self.predict(X))\n",
    "            \n",
    "        print(\"Loss: \", loss)\n",
    "\n",
    "        dy_dm = g.gradient(loss, self.m)\n",
    "        dy_db = g.gradient(loss, self.b)\n",
    "        \n",
    "        self.m.assign_sub(learning_rate * dy_dm)\n",
    "        self.b.assign_sub(learning_rate * dy_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVBVuCtn89-m"
   },
   "source": [
    "We need gradient descent to update our parameters for every iteration. \n",
    "\n",
    "There’s no need to create this algorithm from scratch as Tensorflow has a built in function for this `tf.GradientTape`. By default, GradientTape has persistent set to False which means at most one call can be made to the gradient() method in this object.\n",
    "\n",
    "Since we are using this to calculate for two gradients (one for m and another for b ) for every iteration, we have to set this to True. Then we specify the loss function to which gradients will be computed, in this case mse with parameters `y and self.predict(X)` which represents true and predicted values respectively.\n",
    "\n",
    "Each parameter will be updated by subtracting the product of learning rate and the gradient of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hDWmGwWBA-6"
   },
   "source": [
    "`p_new = p_old - (l*dL/dp)`\n",
    "\n",
    "Learning is a hyperparameter and should be specified when training the linear regressor. The gradient, `dL/dp`, is computed using the gradient() method, which accepts the loss function and the parameter. This operation just solves for the partial derivative of the loss function with respect to the parameter. \n",
    "\n",
    "We have to compute for two gradients in each iteration, one for m and b .\n",
    "To update the parameter with the new value, which is just the `old value minus l*dL/dp`, we simply use `assign_sub() method of tf.Variable`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFQhsHRpPJke"
   },
   "source": [
    "**Train method**\n",
    "\n",
    "Let’s put everything together in a `train` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1635853053921,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "K6QKzfPP86-e"
   },
   "outputs": [],
   "source": [
    "def train(self, X, y, learning_rate=0.01, epochs=5):\n",
    "        \n",
    "        if len(X.shape)==1:\n",
    "            X=tf.reshape(X,[X.shape[0],1])\n",
    "        \n",
    "        self.m.assign([self.var]*X.shape[-1])\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch: \", i)\n",
    "            \n",
    "            self.update(X, y, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzt1b9cqPWD9"
   },
   "source": [
    "First thing that it does is to check if the data only contain a single independent variable; if it is, then it will reshape it to become a 2D tensor.\n",
    "\n",
    "`self.m.assign([self.var]*X.shape[-1])` will initialize m with initial values we set during initialization with a shape following the number of independent variables the data have.\n",
    "\n",
    "The stopping criteria of our algorithm is the number of iteration, defined by epoch . For each iteration, it will call the update method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1635853057455,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "NGodBmIDPP8j"
   },
   "outputs": [],
   "source": [
    "# The entire code of the linear regressor\n",
    "\n",
    "class SimpleLinearRegression:\n",
    "    def __init__(self, initializer='random'):\n",
    "        if initializer=='ones':\n",
    "            self.var = 1.\n",
    "        elif initializer=='zeros':\n",
    "            self.var = 0.\n",
    "        elif initializer=='random':\n",
    "            selfx.var = tf.random.uniform(shape=[], minval=0., maxval=1.)\n",
    "            \n",
    "        self.m = tf.Variable(1., shape=tf.TensorShape(None))\n",
    "        self.b = tf.Variable(self.var)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return tf.reduce_sum(self.m * x, 1) + self.b\n",
    "    \n",
    "    def mse(self, true, predicted):\n",
    "        return tf.reduce_mean(tf.square(true-predicted))\n",
    "    \n",
    "    def update(self, X, y, learning_rate):\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            loss = self.mse(y, self.predict(X))\n",
    "            \n",
    "        print(\"Loss: \", loss)\n",
    "\n",
    "        dy_dm = g.gradient(loss, self.m)\n",
    "        dy_db = g.gradient(loss, self.b)\n",
    "        \n",
    "        self.m.assign_sub(learning_rate * dy_dm)\n",
    "        self.b.assign_sub(learning_rate * dy_db)\n",
    "    \n",
    "    def train(self, X, y, learning_rate=0.01, epochs=5):\n",
    "        \n",
    "        if len(X.shape)==1:\n",
    "            X=tf.reshape(X,[X.shape[0],1])\n",
    "        \n",
    "        self.m.assign([self.var]*X.shape[-1])\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch: \", i)\n",
    "            \n",
    "            self.update(X, y, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ99nSu0QBvf"
   },
   "source": [
    "**Testing our algorithm**\n",
    "\n",
    "It’s time to test our algorithm using the Boston Housing dataset.\n",
    "Load the dataset using keras.datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1635853060617,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "dVImbxCiP9mm",
    "outputId": "66e6ff22-4fd3-49d1-b279-434054ebc957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 2us/step\n",
      "65536/57026 [==================================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1635853064228,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "CxJKACLCQLXV"
   },
   "outputs": [],
   "source": [
    "# Standardize the data:\n",
    "\n",
    "mean_label = y_train.mean(axis=0)\n",
    "std_label = y_train.std(axis=0)\n",
    "mean_feat = x_train.mean(axis=0)\n",
    "std_feat = x_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1635853080781,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "oLacrMihQYWI"
   },
   "outputs": [],
   "source": [
    "x_train_norm = (x_train-mean_feat)/std_feat\n",
    "y_train_norm = (y_train-mean_label)/std_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1635853083076,
     "user": {
      "displayName": "Swastik Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1TarlztnBdahX5CCHNOVZTu3KaYLMf6IWKG9R=s64",
      "userId": "12684891963990309492"
     },
     "user_tz": -330
    },
    "id": "hAgJHJLWRFha",
    "outputId": "7a118695-f105-47b8-94b3-e508a2900ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Loss:  tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "Epoch:  1\n",
      "Loss:  tf.Tensor(0.52037114, shape=(), dtype=float32)\n",
      "Epoch:  2\n",
      "Loss:  tf.Tensor(0.42164913, shape=(), dtype=float32)\n",
      "Epoch:  3\n",
      "Loss:  tf.Tensor(0.3722451, shape=(), dtype=float32)\n",
      "Epoch:  4\n",
      "Loss:  tf.Tensor(0.34227636, shape=(), dtype=float32)\n",
      "Epoch:  5\n",
      "Loss:  tf.Tensor(0.32331648, shape=(), dtype=float32)\n",
      "Epoch:  6\n",
      "Loss:  tf.Tensor(0.31094158, shape=(), dtype=float32)\n",
      "Epoch:  7\n",
      "Loss:  tf.Tensor(0.30257827, shape=(), dtype=float32)\n",
      "Epoch:  8\n",
      "Loss:  tf.Tensor(0.29670173, shape=(), dtype=float32)\n",
      "Epoch:  9\n",
      "Loss:  tf.Tensor(0.2923981, shape=(), dtype=float32)\n",
      "Epoch:  10\n",
      "Loss:  tf.Tensor(0.28911322, shape=(), dtype=float32)\n",
      "Epoch:  11\n",
      "Loss:  tf.Tensor(0.28650656, shape=(), dtype=float32)\n",
      "Epoch:  12\n",
      "Loss:  tf.Tensor(0.28436556, shape=(), dtype=float32)\n",
      "Epoch:  13\n",
      "Loss:  tf.Tensor(0.2825551, shape=(), dtype=float32)\n",
      "Epoch:  14\n",
      "Loss:  tf.Tensor(0.28098768, shape=(), dtype=float32)\n",
      "Epoch:  15\n",
      "Loss:  tf.Tensor(0.27960542, shape=(), dtype=float32)\n",
      "Epoch:  16\n",
      "Loss:  tf.Tensor(0.2783688, shape=(), dtype=float32)\n",
      "Epoch:  17\n",
      "Loss:  tf.Tensor(0.27725047, shape=(), dtype=float32)\n",
      "Epoch:  18\n",
      "Loss:  tf.Tensor(0.2762307, shape=(), dtype=float32)\n",
      "Epoch:  19\n",
      "Loss:  tf.Tensor(0.27529487, shape=(), dtype=float32)\n",
      "Epoch:  20\n",
      "Loss:  tf.Tensor(0.2744321, shape=(), dtype=float32)\n",
      "Epoch:  21\n",
      "Loss:  tf.Tensor(0.27363348, shape=(), dtype=float32)\n",
      "Epoch:  22\n",
      "Loss:  tf.Tensor(0.27289224, shape=(), dtype=float32)\n",
      "Epoch:  23\n",
      "Loss:  tf.Tensor(0.27220258, shape=(), dtype=float32)\n",
      "Epoch:  24\n",
      "Loss:  tf.Tensor(0.27155966, shape=(), dtype=float32)\n",
      "Epoch:  25\n",
      "Loss:  tf.Tensor(0.2709594, shape=(), dtype=float32)\n",
      "Epoch:  26\n",
      "Loss:  tf.Tensor(0.2703983, shape=(), dtype=float32)\n",
      "Epoch:  27\n",
      "Loss:  tf.Tensor(0.26987302, shape=(), dtype=float32)\n",
      "Epoch:  28\n",
      "Loss:  tf.Tensor(0.26938093, shape=(), dtype=float32)\n",
      "Epoch:  29\n",
      "Loss:  tf.Tensor(0.2689195, shape=(), dtype=float32)\n",
      "Epoch:  30\n",
      "Loss:  tf.Tensor(0.26848644, shape=(), dtype=float32)\n",
      "Epoch:  31\n",
      "Loss:  tf.Tensor(0.26807964, shape=(), dtype=float32)\n",
      "Epoch:  32\n",
      "Loss:  tf.Tensor(0.26769727, shape=(), dtype=float32)\n",
      "Epoch:  33\n",
      "Loss:  tf.Tensor(0.2673377, shape=(), dtype=float32)\n",
      "Epoch:  34\n",
      "Loss:  tf.Tensor(0.2669993, shape=(), dtype=float32)\n",
      "Epoch:  35\n",
      "Loss:  tf.Tensor(0.26668057, shape=(), dtype=float32)\n",
      "Epoch:  36\n",
      "Loss:  tf.Tensor(0.26638028, shape=(), dtype=float32)\n",
      "Epoch:  37\n",
      "Loss:  tf.Tensor(0.26609707, shape=(), dtype=float32)\n",
      "Epoch:  38\n",
      "Loss:  tf.Tensor(0.26582992, shape=(), dtype=float32)\n",
      "Epoch:  39\n",
      "Loss:  tf.Tensor(0.26557773, shape=(), dtype=float32)\n",
      "Epoch:  40\n",
      "Loss:  tf.Tensor(0.26533955, shape=(), dtype=float32)\n",
      "Epoch:  41\n",
      "Loss:  tf.Tensor(0.2651145, shape=(), dtype=float32)\n",
      "Epoch:  42\n",
      "Loss:  tf.Tensor(0.2649016, shape=(), dtype=float32)\n",
      "Epoch:  43\n",
      "Loss:  tf.Tensor(0.26470017, shape=(), dtype=float32)\n",
      "Epoch:  44\n",
      "Loss:  tf.Tensor(0.26450953, shape=(), dtype=float32)\n",
      "Epoch:  45\n",
      "Loss:  tf.Tensor(0.26432896, shape=(), dtype=float32)\n",
      "Epoch:  46\n",
      "Loss:  tf.Tensor(0.26415774, shape=(), dtype=float32)\n",
      "Epoch:  47\n",
      "Loss:  tf.Tensor(0.26399544, shape=(), dtype=float32)\n",
      "Epoch:  48\n",
      "Loss:  tf.Tensor(0.26384142, shape=(), dtype=float32)\n",
      "Epoch:  49\n",
      "Loss:  tf.Tensor(0.26369524, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create and train a SimpleLinearRegression object\n",
    "linear_model = SimpleLinearRegression('zeros')\n",
    "linear_model.train(x_train_norm, y_train_norm, learning_rate=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqje3RkVReaW"
   },
   "source": [
    "You may observe the losses from the last 5 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHRfXo8WRv5b"
   },
   "source": [
    "Prediction using the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G8b0tII8Rljo"
   },
   "outputs": [],
   "source": [
    "# standardize\n",
    "x_test_norm = (x_test-mean_feat)/std_feat\n",
    "\n",
    "# reverse standardization\n",
    "pred = linear_model.predict(x_test_norm)\n",
    "pred *= std_label\n",
    "pred += mean_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZPw9dHsSPtP"
   },
   "source": [
    "We have to standardize the input first, then reverse the process once we have the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVO7DLZITPP2",
    "outputId": "7a9670fd-5be3-476e-a49b-9c29a48ec034"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(102,), dtype=float32, numpy=\n",
       "array([ 9.750573 , 21.343346 , 20.710983 , 34.138927 , 25.59863  ,\n",
       "       21.065775 , 28.816599 , 24.816866 , 18.76164  , 22.4953   ,\n",
       "       20.546366 , 18.28501  , 16.986532 , 35.214375 , 18.79039  ,\n",
       "       19.62262  , 24.729702 , 22.466198 , 19.704365 , 24.34065  ,\n",
       "       11.683925 , 16.52935  , 22.132172 , 12.951835 , 21.582878 ,\n",
       "       23.47193  , 33.244553 , 23.863432 , 13.240682 , 21.22096  ,\n",
       "       23.948782 , 18.755093 , 35.82513  , 23.574081 , 18.699013 ,\n",
       "        5.8598137, 14.829306 , 22.739305 , 18.212633 , 27.067528 ,\n",
       "       22.668787 , 28.734303 , 17.822048 , 34.818214 , 30.47356  ,\n",
       "       24.120224 , 29.911219 , 18.132938 , 22.778593 , 23.965012 ,\n",
       "       30.148222 , 18.351568 , 10.182134 , 13.949478 , 34.757175 ,\n",
       "       27.452892 , 18.084135 , 39.978188 , 37.14582  , 24.534048 ,\n",
       "       25.68392  , 20.58696  , 19.966074 , 21.779121 , 24.626728 ,\n",
       "       23.896091 , 17.503538 , 26.206478 ,  5.813816 , 12.12558  ,\n",
       "       24.820618 , 24.470425 , 22.987095 , 10.432622 , 28.194641 ,\n",
       "       20.964315 , 20.89519  , 24.648144 , 33.103413 ,  6.7061443,\n",
       "       23.920465 , 36.532043 , 15.982819 , 18.389572 , 20.380852 ,\n",
       "       18.838015 , 22.092987 , 25.566017 , 23.684172 , 28.575823 ,\n",
       "       17.203    , 17.533667 , 26.548847 , 29.388273 , 34.13365  ,\n",
       "       20.922533 , 35.88112  , 39.4499   , 25.572306 , 41.903168 ,\n",
       "       34.31444  , 25.07185  ], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTfmOU0cTT-d",
    "outputId": "e3c932a0-3531-4d99-d37e-f4efcfd02a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.55369355, -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "        -3.48459553,  2.25092074],\n",
       "       [-0.39242675, -0.48361547, -0.16087773, ..., -0.30759583,\n",
       "         0.42733126,  0.47880119],\n",
       "       [-0.39982927, -0.48361547, -0.86940196, ...,  0.78447637,\n",
       "         0.44807713, -0.41415936],\n",
       "       ...,\n",
       "       [-0.20709507, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "         0.37051949, -1.49344089],\n",
       "       [-0.36698601, -0.48361547, -0.72093526, ..., -0.48960787,\n",
       "         0.39275481, -0.41829982],\n",
       "       [-0.0889679 , -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -1.21946544, -0.40449827]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "habTe8kxSO9Q",
    "outputId": "a83ae71b-9892-45bd-a419-cf1b53a5912c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, pred)\n",
    "plt.plot(range(80), range(80))\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8YDUORgXsYw"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "Despite its simplicity, linear regression is one of the most commonly used machine learning algorithms in the industry. Although there are much simpler ways to implement this algorithm like using scikit-learn and even TensorFlow’s LinearRegressor, we implemented the entire algorithm from scratch with the intent of experiencing TensorFlow’s functions.\n",
    "\n",
    "When you go into neural networks, there are high-level libraries like Keras which simplifies the process of building neural networks using TensorFlow as backend. But eventually, you would want to customize your models however you want it, and this is where the low-level functions of TensorFlow are very useful.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF_Lin_Reg_From_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
